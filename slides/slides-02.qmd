---
title: "√úberblick & Einf√ºhrung"
subtitle: "Session 02"
date: 30 10 2024
date-format: "DD.MM.YYYY"
bibliography: references_slides.bib
---

# Agenda {background-image="img/slide_bg-agenda.png"}

1.  [Organisation & Koordination](#organisation-koordination)
2.  [Die St√§rken von DBD](#dbd-strengths)
3.  [Herausforderungen von DBD](#dbd-challenges)
4.  [üë• Group activity: Wie kommen wir an DBD?](group-activity)

# Organisation & -koordination {#organisation-koordination background-image="img/slide_bg-orga.png"}

Kurzes Update, Gruppenaufteilung & Semesterplan

```{r setup-slide-session}
#| echo: false
# Load packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
    here, 
    tidyverse,
    gt, gtExtras,
    countdown
)

# Load schedule
source(here("slides/schedule.R"))
```

## Kurzes Update

#### Allgemeine Infos zum Kurs

-   Haben alle sich f√ºr die **Pr√ºfung angemeldet?** Gibt es noch Fragen zum Sonderanmeldetermin?

-   Haben alle eine **Benachrichtung** f√ºr den Post im ![](https://www.studon.fau.de/favicon.ico){width="16"} StudOn-Forum bekommen?

-   Haben alle die üìñ **Basisliteratur** gefunden? Gibt es Fragen?

-   Pr√§sentationsgruppe 1&2: Denkt bitte an die Zusendung des **Entwurf der Pr√§sentationsfolien** (bis n√§chsten Dienstag bis 12:00) und das **Feedbackgespr√§ch [n√§chste Woche!]{.underline}**

## Finale Themenvergabe

#### √úberblick √ºber die Gruppenverteilung

<br>

```{r create-table}
#| echo: false

groups <- tibble(
    Gruppe = c("1", "2", "3", "4", "5", "6"),
    Thema = c(
        "Motivation der Nutzung von Twitch",
        "Kommunikation und Interaktion auf Twitch",
        "(Wirkungs-)Effekte der Twitch-Nutzung/Interaktion",
        "(Wirkungs-)Effekte von TV-Wahldebatten",
        "Wechselwirkung zwischen TV-Debatten und Twitter", 
        "Live-Chat(-Kommentare) in politischen Debatten" 
    ), 
    Studierende = c(
        "Azat, Heimst√§dt",
        "Burmeister, Fischer, Erdogmus", 
        "Dierking, Reineke", 
        "Spickenreuther, Wolf", 
        "Gierth, Landgraf", 
        "Mach, Stadler, Wei√ü"
    )
)

groups %>% 
    gt() %>% 
    gt_theme_538() %>% 
    gt::tab_options(
        table.width = gt::pct(100), 
        table.font.size = "22px"
    ) 
```

## Semsterplan

```{r table-schedule}
#| echo: false 

schedule %>%
    gt::gt() %>%
    gt::fmt_markdown(columns = c(Datum, Topic)) %>% 
    gtExtras::gt_theme_538() %>% 
    gt::tab_options(
        table.width = gt::pct(75), 
        table.font.size = "12px"
    ) %>%
    # mark current session
    gtExtras::gt_highlight_rows(
        rows = 3,
        fill = "#C50F3C", 
        alpha = 0.2,
        bold_target_only = TRUE,
        target_col = Topic       
    ) %>% 
    # fade out past sessions
    gt::tab_style(
        style = cell_text(
            style = "italic", 
            color = "grey"),
        location = cells_body(
            columns = everything(), 
            rows = 2)
    )
```

# An Abundance of Possibilities {#dbd-strengths background-image="img/slide_bg-section.png"}

Die St√§rken von Digital Behavioral Data

## Was ist das eigentlich?

#### R√ºckblick auf einen Definitionversuch von @weller2021

::::: columns
::: {.column width="50%"}
... fasst eine Vielzahl von m√∂glichen **Datenquellen** zusammen, die verschiedene **Arten von Aktivit√§ten** aufzeichnen (*h√§ufig sogar "nur" als Nebenprodukt*)

... k√∂nnen dabei helfen, **Meinungen, Verhalten und Merkmale der menschlichen Nutzung** digitaler Technologien zu erkennen
:::

::: {.column width="50%"}
![](img/session-01/dbd_pictogram.svg){fig-align="center"}
:::
:::::

## Und im Kontext des Seminars?

#### Arbeitsdefinition & Kernbereiche ([GESIS](https://www.gesis.org/institut/digitale-verhaltensdaten)) von DBD

::::: columns
::: {.column width="50%" style="font-size: smaller;"}
-   DBD umfasst digitale **Beobachtungen menschlichen und algorithmischen Verhaltens**,
-   wie sie z.B. **von Online-Plattformen** (wie Google, Facebook oder dem World Wide Web) oder
-   **Sensoren** (wie Smartphones, RFID-Sensoren, Satelliten oder Street View-Kameras) erfasst werden.
:::

::: {.column width="50%"}
![](img/session-02/dbd-pillars.png){.caption fig-align="center" width="700"}
:::
:::::


## Die Power von Social Sensing

#### Forschungsdesign zur Erhebung digitaler Verhaltensdaten [@fl√∂ck2022]

::: r-stack
![](img/session-02/graphics/graph_dbd_01.svg){fig-align="center"}

![](img/session-02/graphics//graph_dbd_02.svg){.fragment fragment-index="1" fig-align="center"}

![](img/session-02/graphics//graph_dbd_03.svg){.fragment fragment-index="2" fig-align="center"}

![](img/session-02/graphics//graph_dbd_04.svg){.fragment fragment-index="3" fig-align="center"}

![](img/session-02/graphics//graph_dbd_05.svg){.fragment fragment-index="4" fig-align="center"}

![](img/session-02/graphics//graph_dbd_07.svg){.fragment fragment-index="5" fig-align="center"}
:::

::: notes
Die Zukunft: Linking
:::

## Mit Fokus auf die Platform

#### Forschungsdesign zur Erhebung digitaler Verhaltensdaten [@fl√∂ck2022]

::: r-stack
![](img/session-02/graphics//graph_dbd_08.svg){fig-align="center"}

![](img/session-02/graphics//graph_dbd_09.svg){.fragment fragment-index="2" fig-align="center"}
:::

## Online-Plattformen pr√§gen die Gesellschaft

#### Gr√ºnde f√ºr den Fokus auf Onlineplattformen [@ulloa2021]

<br>

-   vermitteln & formen menschliche Kommunikation (*z.B. Tweet mit 280 Zeichen*)

-   politische (Miss-)Nutzung

-   Gatekeeper f√ºr Informationen (*z.B. "Dr.Google"*)

-   t√§gliche algorithmische Empfehlungen und Werbung: *Nachrichten, Produkte, Jobangebote, Bewerbungen, Versicherungen, Hotels, ...*

::: fragment
#### ABER: Ber√ºcksichtigung der **Art und Weise**, wie die Daten gesammelt werden!
:::

## Eine kleine Lobeshymne auf DBD

#### Zwischenfazit

-   Digitale Ger√§te oder **Sensoren** k√∂nnen sich an bestimmte Fakten **besser "erinnern"** als das menschliche Ged√§chtnis.

-   Sensoren sind oft bereits **in allt√§gliche Technologie eingebaut** und produzieren digitale Verhaltensdaten als ein *"Nebenprodukt"*.

-   Unaufdringliche Erfassung als potentieller Vorteil bzw. **Entlastung f√ºr Teilnehmer\*Innen**

-   **Kombination mit Umfragedaten** m√∂glich (und bereichernd!)

::: fragment
#### Aber: Ber√ºcksichtigung der Rahmenbedingungen!

Zur erfolgreichen Nutzung m√ºssen **Forschungsziele & verf√ºgbare Daten in Einklang** gebracht, m√∂gliche **Biases und methodische Probleme** **ber√ºcksichtigt** sowie die **Datenqualit√§t evaluiert** werden.
:::

::: notes
Bietet die Plattform **Zugang** zu den ben√∂tigten Daten? Wenn nicht, gibt es **alternative Weg** um an die Daten zu gelangen? Wenn ja, ist dies **legal/ethisch**?
:::

# Herausforderungen von DBD {#dbd-challenges background-image="img/slide_bg-section.png"}

Potentielle Biases & ethische und rechtliche Faktoren

## Wenn der Vorteil zum Nachteil wird

#### Ambivalenz der Unaufdringlichkeit [@keusch2021]

-   Unterscheidung zwischen **aufdringlichen** *(z.B. spezielle Research-App & Befragungen)* **& unaufdringlichen** *(z.B. Cookies, Browserplugins & APIs)* **erhobenen Daten**

-   **Bewertung** und Erwartung an Datensammlung ist **abh√§ngig vom Kontex**t (*z.B. Amazon vs. Researchgate*)

::: fragment
#### **Paradoxes Dilemma**

Einerseits **bereitwillige (oft unwissende) Abgabe der Daten an Konzerne** ohne Wissen um deren Weiterverarbeitung, andererseits h√§ufig **Bedenken bez√ºglich Datenschutz & Privatsph√§re bei wissenschaftlichen Studien**, die √ºber Verwendung der Daten aufkl√§ren.
:::

::: notes
Warum? Pers√∂nlicher Nutzen?
:::

## Eher Konzept als Begriff

#### Zur Ambigutit√§t des Begriffes *bias* und dessen Bedeutung im Seminar

::: {style="font-size: smaller;"}
-   *Problem*: **keine klare Grenzen** zwischen den eher **normativen** Konnotationen (z.B. confirmation bias) und der **statistischen** **Bedeutung** des Begriffs (z.B. selection bias)
-   Deswegen: Bewusstsein f√ºr **Ambiguit√§t des Begriffes**
    -   Verwendung in vielen Disziplinen wie der Sozialwissenschaft, der kognitiven Psychologie oder dem Recht
    -   Untersuchung von verschiedenen Ph√§nomenen, wie kognitive Voreingenommenheiten [@croskerry2002] sowie systemische, diskriminierende Ergebnisse [@friedman1996] oder Sch√§den [@barocas2016], aktuell z.B. bei der Verwendung von Machine Learning oder AI.
:::

::: {.callout-important appearance="minimal"}
Verwendung des Begriff haupts√§chlich in seiner statistischen Bedeutung, um auf Verzerrungen in sozialen Daten und deren Analysen hinzuweisen.
:::

## Know your bias!

#### Framework zur Minimierung von Fehlern und Problemen [@olteanu2019]

![](img/session-02/bias_framework_without_legend.png){fig-align="center"}

::: {.notes style="font-size: smaller;"}
Beschreibung:

-   Die Analyse sozialer Daten beginnt mit bestimmten Zielen (Abschnitt 2.1), wie dem Verst√§ndnis oder der Beeinflussung von Ph√§nomenen, die f√ºr soziale Plattformen spezifisch sind (Typ I) und/oder von Ph√§nomenen, die √ºber soziale Plattformen hinausgehen (Typ II).

-   Diese Ziele erfordern, dass die Forschung bestimmte Validit√§tskriterien erf√ºllt, die weiter oben beschrieben wurden (Abschnitt 2.2).

-   Diese Kriterien k√∂nnen ihrerseits durch eine Reihe von allgemeinen Verzerrungen und Problemen beeintr√§chtigt werden (Abschnitt 3).

-   Diese Herausforderungen k√∂nnen von den Merkmalen der einzelnen Datenplattformen (Abschnitt 4) abh√§ngen - die oft nicht unter der Kontrolle der Forschenden stehen - und von den Entscheidungen des Forschungsdesigns entlang einer Datenverarbeitungspipeline (Abschnitte 5 bis 8) - die oft unter der Kontrolle des Forschers stehen.

-   Pfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken
:::

## The biggest problem of them all

#### Potentielle Probleme mit der Qualit√§t der Daten

::: {.callout-important appearance="minimal"}
**Definition Data bias [@olteanu2019]**

A systematic distortion in the sampled data that compromises its representativeness**.**
:::

-   ***Sparsity:*** H√§ufig *Heavy-Tail*-Verteilung, was Analyse am "Kopf" (in Bezug auf h√§ufige Elemente oder Ph√§nomene) erleichtert, am "Schwanz" (wie seltene Elemente oder Ph√§nomene) jedoch erschwert [@baeza-yates2013]

-   ***Noise:*** Unvollst√§ndige, besch√§digte, unzuverl√§ssige oder unglaubw√ºrdige Inhalte [@boyd2012; @naveed2011]

    -   Aber: Unterscheidung von "Noise" und "Signal" ist oft unklar und h√§ngt von der Forschungsfrage ab [@salganik2018]

-   ***Organische vs gemessene Daten:*** Fragen zur Repr√§sentativit√§t (vs. Stichprobenbeschreibung), Kausalit√§t (vs. Korrelation) und Vorhersageg√ºte

## Bias at the source

#### Potentielle Probleme mit der [Datenquelle oder -herkunft]{.rn rn-type="underline" rn-color="#E6002E"}

-   Biases, die auf das **Design und die M√∂glichkeiten der Plattformen** zur√ºckzuf√ºhren sind ([*functional biases*]{.rn rn-type="highlight"}).

-   **Verhaltensnormen**, die auf den **einzelnen Plattformen** bestehen oder sich herausbilden ([*normative biases*]{.rn rn-type="highlight"}).

-   Faktoren, die **au√üerhalb der sozialen Plattformen** liegen, aber das Nutzerverhalten beeinflussen k√∂nnen ([*external biases*]{.rn rn-type="highlight"})

-   Vorhandensein von **nicht-individuellen Konten** ein ([*non-individuals*]{.rn rn-type="highlight"}).

::: {.notes style="font-size: smaller;"}
functional biases:\
- Platform-specific design and features shape user behavior (z.B. Emojis) - Algorithms used for organizing and ranking content influence user behavior - Content presentation influences user behavior (z.B. UI)

normative biases:

-   Norms are shaped by the attitudes and behaviors of online communities, which may be context-dependent (z.B. Partyfotos auf Instagram, aber nicht LinkedIn)
-   The awareness of being observed by others impacts user behavio (Anonymit√§t vs Klarnamen)
-   Social conformity and ‚Äúherding‚Äù happen in social platforms, and such behavioral traits shape user behavior (z.B. Ratings beinflussen eigenes Rating)

external biase:

-   Cultural elements and social contexts are reflected in social datasets. (Zeichenlimit Japan vs. Deutschland)
-   Misinformation and disinformation.
-   Contents on different topics are treated differently.
-   High-impact events, whether anticipated or not, are reflected on social media (z.B. Feiertage)

non-individual-accounts: Organizational accounts, Bots
:::

## Gefangen im Spannungsverh√§ltnis

#### Forschungethik bei digitalen Daten

**Hintergrund**: *Die Herausforderung besteht in der Kombination von zwei extremen Sichtweisen, der Betrachtung der Forschung mit sozialen Daten als "klinische" Forschung oder als Computerforschung*

-   Die Sozialdatenforschung **unterscheidet sich von klinischen Versuchen**.

-   **Ethische Entscheidungen** in der Sozialdatenforschung m√ºssen **gut √ºberlegt sein**, da oft sind mehrere Werte betroffen, die miteinander in Konflikt stehen k√∂nnen

-   Diskussion des Spannungsverh√§ltnisses am Beispiel von drei **spezifischer ethischer Kriterien: Autonomie, Wohlt√§tigkeit und Gerechtigkeit**

::: {.notes style="font-size: smaller;"}
Hintergrund:

1.  Die Sozialdatenforschung √§hnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer F√§higkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden

2.  die Sozialdatenforschung √§hnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.

Punkt 2: Sch√§den, die die √ºblichen Arten der Sozialdatenforschung ( z. B. die Verletzung der Privatsph√§re oder der Anblick verst√∂render Bilder)verursachen k√∂nnen, oft nicht mit Sch√§den von klinischen Versuchen gleichzusetzen

Punkt 3: Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten L√∂sungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015).
:::

## Achtung der individuellen Autonomie

#### Diskussion der *Informierte Zustimmung* als Indikator autonomer Entscheidung

:::: callout-note
## Einwilligung nach Aufkl√§rung setzt voraus, dass

::: {style="font-size: 18px"}
1.  die Forscher\*Innen den potenziellen Teilnehmenden alle **relevanten Informationen offenlegen**;
2.  die potenziellen Teilnehmenden **in der Lage** sind, diese **Informationen zu bewerten;**
3.  die potenziellen Teilnehmenden **freiwillig entscheiden** k√∂nnen, ob sie **teilnehmen** wollen oder nicht;
4.  die Teilnehmenden den Forschernden ihre **ausdr√ºckliche Erlaubnis erteilen**, h√§ufig in schriftlicher Form; und
5.  die Teilnehmende die M√∂glichkeit haben, ihre **Einwilligung jederzeit zur√ºckzuziehen**.
:::
::::

##### **Potentielle Probleme mit Blick auf DBD**

-   Die **Zustimmung** von **Millionen** von Nutzern einzuholen ist **nicht praktikabel.**

-   Die **Nutzungsbedingungen** sozialer Plattformen stellen m√∂glicherweise **keine informierte Zustimmung** zur Forschung dar.

-   Das **√∂ffentliche Teilen** von Inhalten im Internet **bedeutet nicht** unbedingt eine **Zustimmung** zur Forschung.

## No "No" ‚â† "Yes"!

#### Ethische Erw√§gungen bei DBD-Forschung

::: {style="font-size: smaller;"}
**Aus √∂ffentlicher Zug√§nglich- bzw. Verf√ºgbarkeit von Daten leitet sich nicht automatisch ethische Verwertbarkeit ab** [@zimmer2010; @boyd2012]

-   Verletzung der Privatsph√§re der Nutzer [@goroff2015]

-   Erm√∂glichung von rassischem, sozio√∂konomischem oder geschlechtsspezifischem Profiling [@barocas2016]

##### **Negative Beispiele**

-   **Facebook contagion experiment (**2012-2014): Feeds von Nutzer\*Innen so manipulierten, dass sie je nach den ge√§u√üerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten [@kramer2014]

-   **Encore-Forschungsprojekt**: Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen [@burnett2014]
:::

::: {.notes style="font-size: smaller;"}
Hintergrund:

-   Ethische Fragen bisher epistemische Bedenken (Verwendung von nicht schl√ºssigen oder fehlgeleiteten Beweisen), jetzt normativ Bedenken (Folgen der Forschung)
-   Forschung grunds√§tzlich in vielen L√§ndern gesetztlich geregelt

Negativbeispiele:

-   Facebook contagion experiment: Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a).

-   Encore-Forschngsprojekt: Menschen in einigen L√§ndern durch diese Zugriffsversuche m√∂glicherweise gef√§hrdet wurden

Folgende Abschnitte:

-   zentrales Spannungsverh√§ltnis in der Forschungsethik digitaler Daten dargestellt.

-   Anschlie√üend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohlt√§tigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4).
:::

## Wohlt√§tigkeit und Unsch√§dlichkeit als Ziel

#### Bewertung von Risken & Nutzen

**Hintergrund**: *Nicht nur Fokus auf den Nutzen der Forschung, sondern auch auf die m√∂glichen Arten von Sch√§den, die betroffenen Gruppen und die Art und Weise, wie nachteilige Auswirkungen getestet werden k√∂nnen .* [@sweeney2013]

<br>

###### Potentielle Probleme

-   **Daten** √ºber **Einzelpersonen** k√∂nnen ihnen **schaden, wenn** sie **offengelegt** werden.

-   **Forschungsergebnisse** **k√∂nnen** verwendet werden, um **Schaden** anzurichten.

-   **"Dual-Use"- und Sekund√§ranalysen** sind in der Sozialdatenforschung **immer** **h√§ufiger** anzutreffen.

::: {.notes style="font-size: smaller;"}
Die Forschung zu sozialen Daten wird mit bestimmten Arten von Sch√§den in Verbindung gebracht, von denen die Verletzung der Privatsph√§re vielleicht die offensichtlichste ist (Zimmer, 2010; Crawford und Finn, 2014).

Beispiel 1: Einige prominente Beispiele sind die Datenpanne bei Ashley Madison im Jahr 2015, bei der einer Website, die sich als Dating-Netzwerk f√ºr betr√ºgerische Ehepartner anpreist, Kontoinformationen (einschlie√ülich der vollst√§ndigen Namen der Nutzer) gestohlen und online gestellt wurden (Thomsen, 2015), sowie die j√ºngsten Datenpannen bei Facebook, bei denen Hunderte Millionen von Datens√§tzen mit Kommentaren, Likes, Reaktionen, Kontonamen, App-Passw√∂rtern und mehr √∂ffentlich gemacht wurden.

zu 1: - Stalking, Diskriminierung, Erpressung oder Identit√§tsdiebstahl (Gross und Acquisti, 2005). - Zu lange Archivierung personenbezogener Daten oder die √∂ffentliche Freigabe schlecht anonymisierter Datens√§tze kann zu Verletzungen der Privatsph√§re f√ºhren, da diese Daten mit anderen Quellen kombiniert werden k√∂nnen, um Erkenntnisse √ºber Personen ohne deren Wissen zu gewinnen (Crawford und Finn, 2014; Goroff, 2015; Horvitz und Mulligan, 2015)

zu 2: Abgesehen von der Tatsache, dass aus sozialen Daten gezogene R√ºckschl√ºsse in vielerlei Hinsicht falsch sein k√∂nnen, wie in dieser Studie hervorgehoben wird, k√∂nnen zu pr√§zise R√ºckschl√ºsse dazu f√ºhren, dass Menschen in immer kleinere Gruppen eingeteilt werden k√∂nnen (Barocas, 2014).

zu 3: Daten, Instrumente und Schlussfolgerungen, die f√ºr einen bestimmten Zweck gewonnen wurden, f√ºr einen anderen Zweck verwendet werden (Hovy und Spruit, 2016; Benton et al., 2017)
:::

## Faire Verteilung von Risiken & Nutzen

#### Recht & Gerechtigkeit

**Hintergrund**: *H√§ufig wird unterstellt bzw. angenommen, dass es von Anfang an bekannt, wer durch die Forschung belastet und wer von den Ergebnissen profitieren wird.*

<br>

###### Potentielle Probleme

-   Die **digitale Kluft** kann das Forschungsdesign beeinflussen (z.B. *WEIRD Samples*)

-   **Algorithmen** und Forschungsergebnisse k√∂nnen zu **Diskriminierung** f√ºhren.

-   **Forschungsergebnisse** sind m√∂glicherweise **nicht** allgemein **zug√§nglich**.

-   Nicht alle **Interessengruppen** werden √ºber die Verwendung von Forschungsergebnissen konsultiert.

::: {.notes style="font-size: smaller;"}
zu 1: Data divide: mangelnde Verf√ºgbarkeit von hochwertigen Daten √ºber Entwicklungsl√§nder und unterprivilegierte Gemeinschaften (Cinnamon und Schuurman, 2013). WEIRD = White, Educated, Industrialized, Rich, and Democratic

zu 3: Idealerweise sollten die Menschen Zugang zu den Forschungsergebnissen und Artefakten haben, die aus der Untersuchung ihrer pers√∂nlichen Daten entstanden sind (Gross und Acquisti, 2005; Crawford und Finn, 2014).

zu 4: In die √úberlegungen dar√ºber, wie, f√ºr wen und wann Forschungsergebnisse umgesetzt werden, sollten diejenigen einbezogen werden, die m√∂glicherweise betroffen sind oder deren Daten verwendet werden (Costanza-Chock, 2018; Design Justice, 2018; Green, 2018)
:::

## Zwei Trends, Drei Fragen, Vier Empfehlungen

#### Zusammenfassung und Ausblick

**Trend 1: Skepsis gegen√ºber einfachen Antworten**

::: {style="font-size: 22px;"}
1.  Wie einstehen die Daten, was enthalten sie tats√§chlich und wie sind die Arbeitsdatens√§tze zusammengestellt?

2.  Wird deutlich, was ausgewertet wird?

3.  Wird die Verwendung von vorhandenen Datens√§tzen und Modellen des maschinellen Lernens hinterfragt?
:::

**Trend 2: Wechsel von der Thematisierung zur Adressieung von Bedenken**

::: {style="font-size: 22px;"}
1.  **Detaillierte Dokumentation** und kritische **Pr√ºfung** der Datensatz- und Modellerstellung

2.  DBD-Studien auf **verschiedene Plattformen, Themen, Zeitpunkte und Teilpopulationen auszuweiten**, um festzustellen, wie sich die Ergebnisse beispielsweise in verschiedenen kulturellen, demografischen und verhaltensbezogenen Kontexten unterscheiden

3.  **Transparenzmechanismen** zu schaffen, die es erm√∂glichen, Online-Plattformen zu √ºberpr√ºfen und Verzerrungen in Daten an der Quelle zu evaluieren

4.  **Forschung** zu diesen Leitlinien, Standards, Methoden und Protokollen **auszuweiten** und ihre √úbernahme zu f√∂rdern.
:::

::: notes
Schlie√ülich gibt es angesichts der Komplexit√§t der inh√§rent kontextabh√§ngigen, anwendungs- und bereichsabh√§ngigen Verzerrungen und Probleme in sozialen Daten und Analysepipelines, die in diesem Papier behandelt werden, keine Einheitsl√∂sungen - bei der Bewertung und Bek√§mpfung von Verzerrungen ist Nuancierung entscheidend.
:::

# Wie kommen wir an DBD? {#group-activity background-image="img/slide_bg-group_activity.png"}

üë• Group Activity zur Erhebung von DBD

## Der Weg bestimmt das Ergebnis

#### Einfluss der Erhebung auf die Daten(-form) [@davidson2023]

![](img/session-02/graphic-sm_data_access.png){fig-align="center"}

## Data Download Packages

#### Beispiel f√ºr Data Donations [@vandriel2022]

::::: columns
::: {.column width="50%"}
-   [General Data Protection Regulation](https://gdpr.eu/what-is-gdpr/) erlaubt die von einer Plattform gespeicherten personenbezogenen Daten in einem strukturierten, allgemein gebr√§uchlichen und maschienenlesbaren Format (Data Download Package) anzufordern.

-   Nutzer:innen k√∂nnen Forschenden diese Daten spenden, verbunden mit der M√∂glichkeit, bestimmte Daten (heraus) zu filtern.
:::

::: {.column width="50%"}
![](img/session-02/example-ddp.png)
:::
:::::

## Screenomics software

#### Beispiel f√ºr Tracking [@reeves2021]

::::: columns
::: {.column width="50%"}
-   **Erfassung**: Alle f√ºnf Sekunden, in denen digitale Ger√§te aktiviert sind, werden Screenshots erstellt, verschl√ºssel, komprimiert & an einen Forschungsserver √ºbertragen
-   **Verarbeitung**: Screenomics (App) erkennt und segmentiert Text, Gesichter, Logos und Objekte auf den Screenshots
:::

::: {.column width="50%"}
![](img/session-02/example-screenomics.png)
:::
:::::

## Zeeschuimer Plugin

#### Beispiel f√ºr Scraping [@peeters2022]

::::: columns
::: {.column width="60%"}
-   Browsererweiterung, die w√§hrend des Besuchs einer Social-Media-Website Daten √ºber die Elemente sammelt, die in der Weboberfl√§che einer Plattform zu sehen sind

-   Derzeit werden die unter anderem {{< fa brands tiktok >}}, {{< fa brands instagram >}}, {{< fa brands x-twitter >}} & {{< fa brands linkedin >}} unterst√ºtzt

-   Erg√§nzung zu [`4CAT`](https://github.com/digitalmethodsinitiative/4cat) [@peeters2022a], einem Tool zur Analyse und Verarbeitung von Daten aus Online-Plattformen
:::

::: {.column width="40%"}
![](https://raw.githubusercontent.com/digitalmethodsinitiative/zeeschuimer/master/images/example_screenshot.png){fig-align="center"}
:::
:::::

## And now ... you!

#### Gruppenarbeit (ca. 15 Minuten) mit kurzer Ergebnisvorstellung (ca. 15 Min)

::: callout-caution
## Arbeitsauftrag

Stellt euch vor, Ihr wollt **eine der drei vorgestellten Methoden** nutzen, um ein **Forschungsprojekt** **durchzuf√ºhren**.

-   Was sind **m√∂gliche Biases an der Quelle der Daten**, die ihr bei der Methode ber√ºcksichtigen m√ºsst?

-   Welche **ethischen und rechtlichen Fragen** ergeben sich aus der Nutzung der Methode?
:::

::: callout-note
## N√§chste Schritte

-   Es gibt f√ºr jede Methode (Data Donation, Tracking & Scraping) eine Gruppe. Ihr k√∂nnt selber aussuchen, in welche Gruppe ihr m√∂chtet.

-   Schreibt eure Ergebnisse in die daf√ºr bereitgestellet Folienvorlage (auf der n√§chsten Slide).
:::

## Please discuss!

#### Bitte nutzt die jeweilige Folienvorlage f√ºr die Dokumentation euerer Ergebnisse

<br>

::: columns
::: {.column width="30%"}
{{< qrcode https://t1p.de/ldvng qr1 width=300 height=300 colorDark='#C50F3C' >}} [Data Donations](https://t1p.de/ldvng)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
{{< qrcode https://t1p.de/m040h qr2 width=300 height=300 colorDark='#18B4F1' >}} [Tracking](https://t1p.de/m040h)
:::

::: {.column width="5%"}
:::

::: {.column width="30%"}
{{< qrcode https://t1p.de/qbmjw qr4 width=300 height=300 colorDark='#FDB735' >}} [Scraping](https://t1p.de/qbmjw)
:::
:::

```{r countdown-vote}
#| echo: false

countdown(
    minutes = 15,
    warn_when = 300,
    update_every = 10,
    bottom = 0)
```



# Time for questions {background-image="img/slide_bg-question.png"}


# Bis zur n√§chsten Sitzung! {background-image="img/slide_bg-end_session.png"}


## Literatur

::: {#refs}
:::